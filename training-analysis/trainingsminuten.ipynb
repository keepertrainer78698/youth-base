{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('env')",
   "metadata": {
    "interpreter": {
     "hash": "2ee736e6460c18009aceec69817ca5390d5e9860f9b4585979ff241c3f9cb44d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fnmatch\n",
    "import os\n",
    "import csv\n",
    "import codecs\n",
    "import boto3\n",
    "import io\n",
    "from io import StringIO"
   ]
  },
  {
   "source": [
    "# Load and Cleansing of Training Data"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ln: config.py: File exists\n"
     ]
    }
   ],
   "source": [
    "# Load from S3\n",
    "!ln -s /Users/matthiashugli/Virtualenvs/youth-base/youth-base/config.py config.py\n",
    "from config import s3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\ns3.Bucket(name='training-minutes')\n"
     ]
    }
   ],
   "source": [
    "# Get all CSV Files in the subfolder rawdata/\n",
    "bucket_name = s3.Bucket('training-minutes')\n",
    "\n",
    "bucket_list = []\n",
    "for file in bucket_name.objects.filter(Prefix = 'rawdata/'):\n",
    "    file_key = file.key\n",
    "    if file_key.find('.csv') != -1:\n",
    "        bucket_list.append(file.key)\n",
    "length_bucket_list = print(len(bucket_list))\n",
    "print(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'AQHR2FJQENX6MD3Z',\n",
       "  'HostId': 'xieVhMC3CVXEhJxLSpWf0yfxviSNIFoKSSLlErLN8NNdJZiEZwB/NS3mJN/Tpj1g3xcsj1+voz8=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'xieVhMC3CVXEhJxLSpWf0yfxviSNIFoKSSLlErLN8NNdJZiEZwB/NS3mJN/Tpj1g3xcsj1+voz8=',\n",
       "   'x-amz-request-id': 'AQHR2FJQENX6MD3Z',\n",
       "   'date': 'Thu, 25 Mar 2021 06:20:10 GMT',\n",
       "   'etag': '\"d41d8cd98f00b204e9800998ecf8427e\"',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"d41d8cd98f00b204e9800998ecf8427e\"'}"
      ]
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for file_name in bucket_list:\n",
    "    obj = s3.Object(bucket_name.name, file_name)\n",
    "    data = obj.get()['Body'].read()\n",
    "    file = pd.read_csv(io.BytesIO(data), header=1, delimiter=',', low_memory=False)\n",
    "\n",
    "    df = df.append(file)\n",
    "\n",
    "## Save to csv file as staging file\n",
    "df.to_csv('trainings.csv', encoding='utf-8')\n",
    "csv_buffer = StringIO()\n",
    "s3.Object(bucket_name.name, 'staging_trainings.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   FE-14 BSC YOUNG BOYS       Jan Uebersax  Tor    0 value\n0  FE-14 BSC YOUNG BOYS   Elia Pietropaolo  Tor  NaN   NaN\n1    U17 BSC Young Boys  Mario Baumgartner  Tor  NaN   NaN\n2    U17 BSC Young Boys  Elio Castro Baldo  Tor  NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "df.columns = df.iloc[0]\n",
    "\n",
    "df = df[1:]\n",
    "df = df.melt(df.columns[0:3])\n",
    "\n",
    "print(df.head(3))\n",
    "df.to_csv('test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    file = file.iloc[2:]\n",
    "    file = file.rename(columns=lambda c: c.replace('.1', '.number_trainings') if fnmatch.fnmatch(c, '*.1') else c + \".duration\")\n",
    "    file = file.melt(file.columns[0:3])\n",
    "    file.insert(0, 'filename', file_name)"
   ]
  },
  {
   "source": [
    "# Load from S3\n",
    "!ln -s /Users/matthiashugli/Virtualenvs/youth-base/youth-base/config.py config.py\n",
    "from config import s3\n",
    "\n",
    "bucket_name = 'training-minutes'\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for obj in s3.Bucket(bucket_name).objects.all():\n",
    "    ## List all files and convert them to Dataframe\n",
    "    if obj.key[-5:] == '.csv':\n",
    "        data = s3.Bucket(bucket_name).Object(obj.key).get()\n",
    "        file = pd.read_csv(data['body'])\n",
    "        filename = obj.key\n",
    "\n",
    "        ## Cleansing of File\n",
    "        ### Remove unnecessary rows, label duration and count measure columns correctly and transpose into long\n",
    "        file = file.iloc[2:]\n",
    "        file = file.rename(columns=lambda c: c.replace('.1', '.number_trainings') if fnmatch.fnmatch(c, '*.1') else c + \".duration\")\n",
    "        file = file.melt(file.columns[0:3])\n",
    "\n",
    "        ### Properly Name columns and categories\n",
    "        file[['skills', 'entity']] = file.variable.apply(lambda x: pd.Series(str(x).split('.')))\n",
    "        file = file.drop(columns=['Category Name.duration', 'variable'])\n",
    "        file = file.rename(columns={'Unnamed: 0.duration': 'team', 'Unnamed: 1.duration': 'keeper'})\n",
    "\n",
    "        ### Pivot file for all categories and create two columns for duration in minutes and number of trainings\n",
    "        file = file.pivot(index=['team', 'keeper', 'skills'], columns='entity', values='value').reset_index()\n",
    "\n",
    "        ### Clean catgegory and date columns\n",
    "        file[['team', 'club']] = file.team.str.split(' BSC', 1, expand=True)\n",
    "        file[['team', 'club']] = file.team.str.split(' YB', 1, expand=True)\n",
    "        file['filename'] = filename\n",
    "        file[['file', 'type']] = file.filename.apply(lambda x: pd.Series(str(x).split('.')))\n",
    "        file['yearmonth'] = file.file.str[-6:]\n",
    "        file['date'] = pd.to_datetime(file.yearmonth, format='%Y%m', errors='coerce').dropna()\n",
    "        file['year'] = pd.DatetimeIndex(file['date']).year\n",
    "        file['month'] = file.date.dt.month_name()\n",
    "\n",
    "        ### Drop all helping columns and values with NaN\n",
    "        file = file.drop(columns=['filename', 'file', 'type', 'club'])\n",
    "        file = file.dropna(subset=['number_trainings', 'duration'])\n",
    "\n",
    "        ### append cleansed file into one Dataframe\n",
    "        df = df.append(file)\n",
    "\n",
    "## Save to csv file\n",
    "df.to_csv('trainings.csv', encoding='utf-8')\n",
    "csv_buffer = StringIO()\n",
    "s3.Object(bucket_name, 'trainings.csv').put(Body=csv_buffer.getvalue())\n",
    "   "
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 83,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ln: config.py: File exists\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '5227Y3FZMVKMW43X',\n",
       "  'HostId': 'VfRf1sZpFyElgjpeLratLWn8M44ObjnjaLFUd+rO8BRnMnSnf7VtvKc26GKzvBK4uK9azuXJTo0=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'VfRf1sZpFyElgjpeLratLWn8M44ObjnjaLFUd+rO8BRnMnSnf7VtvKc26GKzvBK4uK9azuXJTo0=',\n",
       "   'x-amz-request-id': '5227Y3FZMVKMW43X',\n",
       "   'date': 'Thu, 25 Mar 2021 06:07:21 GMT',\n",
       "   'etag': '\"d41d8cd98f00b204e9800998ecf8427e\"',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"d41d8cd98f00b204e9800998ecf8427e\"'}"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Outdated!!! Read from local files, however files are stored on S3 from March 2021\n",
    "\n",
    "path = '/Users/matthiashugli/Virtualenvs/youth-base/youth-base/training-analysis/data'\n",
    "\n",
    "data = [os.path.join(dirpath, f) for dirpath, dirnames, files in os.walk(path) for f in fnmatch.filter(files, '*.xlsx')]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for filename in data:\n",
    "    file = pd.read_excel(filename, sheet_name='s1_core_trm_player_unit_skills', index_col=None, header=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'awsglue'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2b1593cd3df2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ETL Job in AWS glue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mawsglue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mawsglue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetResolvedOptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'awsglue'"
     ]
    }
   ],
   "source": [
    "# ETL Job in AWS glue\n",
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "\n",
    "## @params: [TempDir, JOB_NAME]\n",
    "args = getResolvedOptions(sys.argv, ['JOB_NAME'])\n",
    "\n",
    "glueContext = glueContext(SparkContext.getOrCreate())\n",
    "glueJob = Job(glueContext)\n",
    "\n",
    "glueJob.init(args['JOB_NAME'], args)\n",
    "\n",
    "## ETL\n",
    "!ln -s /Users/matthiashugli/Virtualenvs/youth-base/youth-base/config.py config.py\n",
    "from config import s3\n",
    "\n",
    "bucket_name = 'training-minutes'\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for obj in s3.Bucket(bucket_name).objects.all():\n",
    "    ## List all files and convert them to Dataframe\n",
    "    data = s3.Bucket(bucket_name).Object(obj.key).get()\n",
    "    file = pd.read_excel(io.BytesIO(data['Body'].read()), sheet_name='s1_core_trm_player_unit_skills', index_col=None, header=1)\n",
    "    filename = obj.key\n",
    "\n",
    "    ## Cleansing of File\n",
    "    ### Remove unnecessary rows, label duration and count measure columns correctly and transpose into long\n",
    "    file = file.iloc[2:]\n",
    "    file = file.rename(columns=lambda c: c.replace('.1', '.number_trainings') if fnmatch.fnmatch(c, '*.1') else c + \".duration\")\n",
    "    file = file.melt(file.columns[0:3])\n",
    "\n",
    "    ### Properly Name columns and categories\n",
    "    file[['skills', 'entity']] = file.variable.apply(lambda x: pd.Series(str(x).split('.')))\n",
    "    file = file.drop(columns=['Category Name.duration', 'variable'])\n",
    "    file = file.rename(columns={'Unnamed: 0.duration': 'team', 'Unnamed: 1.duration': 'keeper'})\n",
    "\n",
    "    ### Pivot file for all categories and create two columns for duration in minutes and number of trainings\n",
    "    file = file.pivot(index=['team', 'keeper', 'skills'], columns='entity', values='value').reset_index()\n",
    "\n",
    "    ### Clean catgegory and date columns\n",
    "    file[['team', 'club']] = file.team.str.split(' BSC', 1, expand=True)\n",
    "    file[['team', 'club']] = file.team.str.split(' YB', 1, expand=True)\n",
    "    file['filename'] = filename\n",
    "    file[['file', 'type']] = file.filename.apply(lambda x: pd.Series(str(x).split('.')))\n",
    "    file['yearmonth'] = file.file.str[-6:]\n",
    "    file['date'] = pd.to_datetime(file.yearmonth, format='%Y%m', errors='coerce').dropna()\n",
    "    file['year'] = pd.DatetimeIndex(file['date']).year\n",
    "    file['month'] = file.date.dt.month_name()\n",
    "\n",
    "    ### Drop all helping columns and values with NaN\n",
    "    file = file.drop(columns=['filename', 'file', 'type', 'club'])\n",
    "    file = file.dropna(subset=['number_trainings', 'duration'])\n",
    "\n",
    "    ### append cleansed file into one Dataframe\n",
    "    df = df.append(file)\n",
    "\n",
    "print(df.head(3))\n",
    "\n",
    "\n",
    "\n",
    "glueJob.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}